# -*- coding: utf-8 -*-
"""CLT_Reviews_Text_Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZlzBs42SKjL14DVzOlWzuWGzVc4YbGsl

#### Install Relevant Libraries
"""

!pip install nltk gensim wordcloud matplotlib
!pip install statsmodels
!pip install seaborn

"""#### Import relevant packages"""

# Import libraries
import numpy as np
import pandas as pd
import statsmodels.api as sm
import seaborn as sns
import matplotlib.pyplot as plt
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from gensim.models import Word2Vec
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Read data
df = pd.read_csv("/content/CLT_Res_Reviews.csv", encoding='ISO-8859-1')
df.head()

df.info()

"""Run preprocessing and generate the WordCloud on a food plate shape."""

# Required Libraries
from PIL import Image
from wordcloud import WordCloud, ImageColorGenerator

# Preprocessing function to clean the text
def preprocess_text(text):
    # Lowercase the text
    text = text.lower()
    # Remove non-alphabetic characters and extra spaces
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # Tokenize the text
    tokens = word_tokenize(text)
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [word for word in tokens if word not in stop_words and len(word) > 2]
    return filtered_tokens

# Apply the preprocessing to the 'text' column
df['cleaned_text'] = df['text'].apply(preprocess_text)

# Train a Word2Vec model on the preprocessed text
# List of tokenized reviews (Word2Vec expects a list of lists)
sentences = df['cleaned_text'].tolist()

# Train the Word2Vec model
model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4)

# Check similar words to a sample word (e.g., "food")
print(model.wv.most_similar("food"))

# Generate WordCloud for visualization
# Join all words from the cleaned_text column
all_words = ' '.join([' '.join(text) for text in df['cleaned_text']])

# Load the food plate-shaped mask image
food_plate_mask = np.array(Image.open("/content/food_plate_image.png"))

# Create the WordCloud with the food plate mask
wordcloud = WordCloud(width=800, height=800, background_color='white', max_words=100, mask=food_plate_mask, contour_width=1, contour_color='black').generate(all_words)

# Plot the WordCloud
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')  # Remove axes
plt.show()